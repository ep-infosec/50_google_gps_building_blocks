# Airflow custom hooks and operators


## Using AutoML Batch Prediction Operator

After you trained you model using the AutoML Tables
[web UI](https://pantheon.corp.google.com/automl-tables/datasets), a model is
saved with a model id. To predict, you need to simply specify these parameters:

-   `input_path`: Where your data is located.
-   `output_path`: Where the prediction result will be written to.
-   `model_id`: The model id.
-   `conn_id`: The
    [GCP connection id](https://airflow.apache.org/howto/connection/gcp.html)
    for authentication. Can be created using the
    [Airflow admin UI](https://airflow.apache.org/howto/connection/index.html).

```python
import AutoMLTablesBatchPredictionOperator
op = AutoMLTablesBatchPredictionOperator(
    model_id='my_model_id',

    # input data from BigQuery
    input_path='bq://project.dataset/table',

    # or: input data from Google Cloud Storage
    # input_path='gs://path/to/input',

    # output prediction result to BigQuery
    output_path='bq://project.dataset/table',

    # or: output data to Google Cloud Storage
    # output_path='gs://path/to/output',

    conn_id='google_cloud_default'
)
```

### Using the AutoML Batch Prediction Operator in a Pipeline

When using the prediction operator in a data pipeline (i.e. an Airflow DAG), you
might encounter these problems:

1.  How can I use input data from an upstream task (for example, a data
    preprocessing operator)?
2.  The output of AutoML predictions is generated by the API server. How can the
    downstream task know where the output data is?

To facilitate this, we used Airflow's builtin mechanism
[xcom](https://airflow.apache.org/concepts.html#xcoms) to pass execution status
between tasks. Think of it as return values for traditional functions.

To match input and output between tasks, specify `input_key` and `output_key` to
the operators:

```python
op1 = DataProcessOp(
    input_path='/path/to/data',
    output_key='input_data')
op2 = AutoMLTablesBatchPredictionOperator(
    input_key='input_data',
    output_key='predict_result')
op3 = PostProcessOp(
    input_key='predict_result',
    output_path='/path/to/result')

op1 >> op2 >> op3
```
