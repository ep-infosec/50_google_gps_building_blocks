# Data Visualizer Component ML Windowing pipeline

## Overview

Quality of ML models depends heavily on the quality of the training data. This
component helps ML model developers to explore a dataset thoroughly and
efficiently for quality and consistency, and decide which variables and periods
of data to use to create ML datasets. Specifically, it helps to explore the
inputs and outputs data of the
[ML Windowing Pipeline component](https://github.com/google/gps_building_blocks/tree/master/py/gps_building_blocks/ml/data_prep/ml_windowing_pipeline).

NOTE: This module currently supports exploring datasets for binary
classification and regression models. To use this module data needs to be stored
in Google Cloud BigQuery.

This component has 3 main modules:

1.  [Instance visualizer](#instance-visualizer): used to visualize the
    statistics calculated from the ML instances in the Instance Table generated
    by the Data Exploration Pipeline of the
    [ML Windowing Pipeline component](py/gps_building_blocks/ml/data_prep/ml_windowing_pipeline).
2.  [Fact visualizer](#fact-visualizer): used to visualize the statistics
    calculated from the numerical and categorical Fact Tables generated by the
    Data Exploration Pipeline of the
    [ML Windowing Pipeline component](py/gps_building_blocks/ml/data_prep/ml_windowing_pipeline).
3.  [Feature visualizer](#feature-visualizer): used to visualize the statistics
    calculated from the Features Table generated by the Features Pipeline of the
    [ML Windowing Pipeline component](py/gps_building_blocks/ml/data_prep/ml_windowing_pipeline)
    or any BigQuery table containing features and the label.

## Installation

```bash
pip install gps_building_blocks
```

## Usage examples

### Instance visualizer

Instance table in BigQuery is created by the `Data Exploration Pipeline` of
[ML Windowing Pipeline component](py/gps_building_blocks/ml/data_prep/ml_windowing_pipeline).
Instance table contains the instances extracted for modeling over one or more
snapshot dates, their labels and two features, namely,
`days_since_first_activity` and `days_since_latest_activity`.

**Usage**

```python
from google.cloud import bigquery
from matplotlib.backends.backend_pdf import PdfPages
from gps_building_blocks.ml.data_prep.data_visualizer import instance_visualizer

bq_client = bigquery.Client()

# with binary label
instance_viz = instance_visualizer.InstanceVisualizer(
        bq_client=bq_client,
        instance_table_path='project_id.dataset.instance_table',
        num_instances=100000,
        label_column='label',
        label_type='binary',
        positive_class_label=True,
        negative_class_label=False)

# with numerical label
instance_viz = instance_visualizer.InstanceVisualizer(
        bq_client=bq_client,
        instance_table_path='project_id.dataset.instance_table',
        num_instances=100000,
        label_column='label',
        label_type='numerical')

instance_plots = instance_viz.plot_instances()

# save the plots to a pdf file
pdf = PdfPages('instance_plots.pdf')
pdf.savefig(instance_plots[0].get_figure())
pdf.close()
```

**Expected output:**

With binary label this generates plots with the number of total instances,
number of positive instances and proportion of positive instances for each
snapshot. With numeric label the plots contain number of total instances and the
distribution of the label (box plots) for each snapshot. These plots are helpful
to understand how the label is distributed over time, any seasonality and trends
and whether there are any inconsistencies. Based on this we can drop specific
periods of snapshots having any data issues and consider what additional
features to add to capture the seasonality or any trends of the label over time.

In addition, this function also produces distribution plots (per class plots
when the label is binary and one plot for all instances when the label is
numerical) for the `days_since_first_activity` and `days_since_latest_activity`
features in the Instance table. From these plots, we can determine a good
lookback window period to use to create features and whether itâ€™s worth only
using customers having a particular history and recency for modeling.

Expected plots with a binary label:
<img src="images/instance_plots_binary_label.png" width="60%">

Expected plots with a numerical label:
<img src="images/instance_plots_numerical_label.png" width="60%">

### Fact visualizer

Facts table in BigQuery is created by the `Data Exploration Pipeline` of
`ML Windowing Pipeline`, which contains the original GA variable transformed into
*facts* format containing `user_id`, `timestamp`, `fact_name` and `fact_value`.

**Usage**

```python
from google.cloud import bigquery
from matplotlib.backends.backend_pdf import PdfPages
from gps_building_blocks.ml.data_prep.data_visualizer import fact_visualizer

bq_client = bigquery.Client()
fact_viz = fact_visualizer.FactVisualizer(
        bq_client=bq_client,
        numerical_facts_table_path='project_id.dataset.numerical_facts',
        categorical_facts_table_path='project_id.dataset.categorical_facts',
        number_top_categories=5)

numerical_fact_plots = fact_viz.plot_numerical_facts()
categorical_fact_plots = fact_viz.plot_categorical_facts()

# save the plots to a pdf files
pdf = PdfPages('numerical_fact_plots.pdf')
for num_plots in numerical_fact_plots:
  pdf.savefig(num_plots[0].get_figure())
pdf.close()

pdf = PdfPages('categorical_fact_plots.pdf')
for cat_plots in categorical_fact_plots:
  pdf.savefig(cat_plots[0].get_figure())
pdf.close()
```

**Expected output:**

`plot_numerical_facts()` and `plot_categorical_facts()` functions produces plots
of numerical and categorical fact variables, which can be used to explore their
validity and distribution over time. Based on that we can make decisions such as
which facts variables (and which levels in categorical fact variables) to use to
generate features later on.

Expected plots for a numerical fact:

<img src="images/numerical_fact_plots.png" width="60%">

Expected plots for a categorical fact:

<img src="images/categorical_fact_plots.png" width="60%">

### Feature visualizer

This module can be used to visualize the statistics calculated from the Features
Table generated by the `Features Pipeline` of the `ML Windowing Pipeline` tool
or any BigQuery table containing the features and the label (binary or
numerical) columns.

**Usage**

```python
from google.cloud import bigquery
from gps_building_blocks.ml.data_prep.data_visualizer import feature_visualizer
from matplotlib.backends.backend_pdf import PdfPages

bq_client = bigquery.Client()

# with binary label
feature_viz = feature_visualizer.FeatureVisualizer(
        bq_client=sbq_client,
        features_table_path='project_id.dataset.features_table',
        numerical_features=('num_feature_1', 'num_feature_2', 'num_feature_3'),
        categorical_features=(
            'cat_feature_1', 'cat_feature_2', 'cat_feature_3'),
        label_column='label',
        label_type='binary',
        positive_class_label=True,
        negative_class_label=False,
        num_pos_instances=10000,
        num_neg_instances=10000)

# with numerical label
feature_viz = feature_visualizer.FeatureVisualizer(
        bq_client=sbq_client,
        features_table_path='project_id.dataset.features_table',
        numerical_features=('num_feature_1', 'num_feature_2', 'num_feature_3'),
        categorical_features=(
            'cat_feature_1', 'cat_feature_2', 'cat_feature_3'),
        label_column='label',
        label_type='numerical',
        num_instances=10000)

feqture_plots = feature_viz.plot_features()

# save the plots to a pdf files
pdf = PdfPages('feature_plots.pdf')
for plots in feature_plots:
  pdf.savefig(plots[0].get_figure())
pdf.close()
```

**Expected output:**

This function produces distribution plots (per class plots
when the label is binary and one plot for all instances when the label is
numerical) of numerical and categorical features, which can be used to explore
the validity of the features and potentially identify issues such as label
leakage (the features that are suspiciously correlated with the label). Also it
produces the distribution of these features over time helping us to understand
their consistency and drop any inconsistent features.

Expected plots for a numerical feature with a binary label:

<img src="images/num_feature_plots_binary_label.png" width="60%">

Expected plots for a categorical feature with a binary label:

<img src="images/cat_feature_plots_binary_label.png" width="60%">

Expected plots for a numerical feature with a numerical label:

<img src="images/num_feature_plots_numerical_label.png" width="60%">

Expected plots for a categorical feature with a numerical label:

<img src="images/cat_feature_plots_numerical_label.png" width="60%">
